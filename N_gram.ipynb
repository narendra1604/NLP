{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91832\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_smoke = \"did you know there was a tower , where they look out to the land, To see the people quickly passing by\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['did',\n",
       " 'you',\n",
       " 'know',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'tower',\n",
       " ',',\n",
       " 'where',\n",
       " 'they',\n",
       " 'look',\n",
       " 'out',\n",
       " 'to',\n",
       " 'the',\n",
       " 'land',\n",
       " ',',\n",
       " 'To',\n",
       " 'see',\n",
       " 'the',\n",
       " 'people',\n",
       " 'quickly',\n",
       " 'passing',\n",
       " 'by']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black_smoke_tokens = word_tokenize(black_smoke)\n",
    "black_smoke_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('did', 'you'),\n",
       " ('you', 'know'),\n",
       " ('know', 'there'),\n",
       " ('there', 'was'),\n",
       " ('was', 'a'),\n",
       " ('a', 'tower'),\n",
       " ('tower', ','),\n",
       " (',', 'where'),\n",
       " ('where', 'they'),\n",
       " ('they', 'look'),\n",
       " ('look', 'out'),\n",
       " ('out', 'to'),\n",
       " ('to', 'the'),\n",
       " ('the', 'land'),\n",
       " ('land', ','),\n",
       " (',', 'To'),\n",
       " ('To', 'see'),\n",
       " ('see', 'the'),\n",
       " ('the', 'people'),\n",
       " ('people', 'quickly'),\n",
       " ('quickly', 'passing'),\n",
       " ('passing', 'by')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.bigrams(black_smoke_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('did', 'you', 'know'),\n",
       " ('you', 'know', 'there'),\n",
       " ('know', 'there', 'was'),\n",
       " ('there', 'was', 'a'),\n",
       " ('was', 'a', 'tower'),\n",
       " ('a', 'tower', ','),\n",
       " ('tower', ',', 'where'),\n",
       " (',', 'where', 'they'),\n",
       " ('where', 'they', 'look'),\n",
       " ('they', 'look', 'out'),\n",
       " ('look', 'out', 'to'),\n",
       " ('out', 'to', 'the'),\n",
       " ('to', 'the', 'land'),\n",
       " ('the', 'land', ','),\n",
       " ('land', ',', 'To'),\n",
       " (',', 'To', 'see'),\n",
       " ('To', 'see', 'the'),\n",
       " ('see', 'the', 'people'),\n",
       " ('the', 'people', 'quickly'),\n",
       " ('people', 'quickly', 'passing'),\n",
       " ('quickly', 'passing', 'by')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.trigrams(black_smoke_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('did', 'you', 'know', 'there'),\n",
       " ('you', 'know', 'there', 'was'),\n",
       " ('know', 'there', 'was', 'a'),\n",
       " ('there', 'was', 'a', 'tower'),\n",
       " ('was', 'a', 'tower', ','),\n",
       " ('a', 'tower', ',', 'where'),\n",
       " ('tower', ',', 'where', 'they'),\n",
       " (',', 'where', 'they', 'look'),\n",
       " ('where', 'they', 'look', 'out'),\n",
       " ('they', 'look', 'out', 'to'),\n",
       " ('look', 'out', 'to', 'the'),\n",
       " ('out', 'to', 'the', 'land'),\n",
       " ('to', 'the', 'land', ','),\n",
       " ('the', 'land', ',', 'To'),\n",
       " ('land', ',', 'To', 'see'),\n",
       " (',', 'To', 'see', 'the'),\n",
       " ('To', 'see', 'the', 'people'),\n",
       " ('see', 'the', 'people', 'quickly'),\n",
       " ('the', 'people', 'quickly', 'passing'),\n",
       " ('people', 'quickly', 'passing', 'by')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.ngrams(black_smoke_tokens, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wine', 'studi', 'buy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('wining'), pst.stem('studies'), pst.stem('buying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\91832\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\91832\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import wordnet\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_stem = ['cats', 'cacti', 'geese']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats:cat\n",
      "cacti:cactus\n",
      "geese:goose\n"
     ]
    }
   ],
   "source": [
    "for i in words_to_stem:\n",
    "    print(i + \":\" + lemmatizer.lemmatize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "peace = \"what do you mean, i do belive in god? IO talm to him everyday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'do',\n",
       " 'you',\n",
       " 'mean',\n",
       " ',',\n",
       " 'i',\n",
       " 'do',\n",
       " 'belive',\n",
       " 'in',\n",
       " 'god',\n",
       " '?',\n",
       " 'IO',\n",
       " 'talm',\n",
       " 'to',\n",
       " 'him',\n",
       " 'everyday']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peace_tokens = word_tokenize(peace)\n",
    "peace_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('what', 'WP')]\n",
      "[('do', 'VB')]\n",
      "[('you', 'PRP')]\n",
      "[('mean', 'NN')]\n",
      "[(',', ',')]\n",
      "[('i', 'NN')]\n",
      "[('do', 'VB')]\n",
      "[('belive', 'NN')]\n",
      "[('in', 'IN')]\n",
      "[('god', 'NN')]\n",
      "[('?', '.')]\n",
      "[('IO', 'NN')]\n",
      "[('talm', 'NN')]\n",
      "[('to', 'TO')]\n",
      "[('him', 'PRP')]\n",
      "[('everyday', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "for i in peace_tokens:\n",
    "    print(nltk.pos_tag([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mary = \"mary had a little lamp, whom she really love\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mary_tokens = word_tokenize(mary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mary', 'NN')]\n",
      "[('had', 'VBD')]\n",
      "[('a', 'DT')]\n",
      "[('little', 'JJ')]\n",
      "[('lamp', 'NN')]\n",
      "[(',', ',')]\n",
      "[('whom', 'WP')]\n",
      "[('she', 'PRP')]\n",
      "[('really', 'RB')]\n",
      "[('love', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "for i in mary_tokens:\n",
    "    print(nltk.pos_tag([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
